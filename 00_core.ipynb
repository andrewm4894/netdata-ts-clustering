{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from tslearn.clustering import TimeSeriesKMeans\n",
    "from netdata_pandas.data import get_data, get_chart_list\n",
    "from am4894plots.plots import plot_lines_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Clusterer:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 hosts: list, charts: list, after: int, before: int, diff: bool = False, norm: bool = True, \n",
    "                 smooth_n: int = 5, smooth_func: str = 'mean', n_clusters: int = 10, min_n: int = 3, \n",
    "                 max_n: int = 100, min_qs: float = 0.5):\n",
    "        self.hosts = hosts\n",
    "        self.charts = charts\n",
    "        self.after = after\n",
    "        self.before = before\n",
    "        self.diff = diff\n",
    "        self.norm = norm\n",
    "        self.smooth_n = smooth_n\n",
    "        self.smooth_func = smooth_func\n",
    "        self.n_clusters = n_clusters\n",
    "        self.min_n = min_n\n",
    "        self.max_n = max_n\n",
    "        self.min_qs = min_qs\n",
    "        self.cluster_quality_dict = {}\n",
    "        \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.df = get_data(self.hosts, self.charts, after=self.after, before=self.before, user=None, pwd=None)\n",
    "        # remove duplicate columns that we might get from get_data()\n",
    "        self.df = self.df.loc[:,~self.df.columns.duplicated()]\n",
    "        # drop any empty columns\n",
    "        self.df = self.df.dropna(axis=1, how='all')\n",
    "        # forward fill and backward fill to try remove any N/A values\n",
    "        self.df = self.df.ffill().bfill()\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.diff:\n",
    "            self.df = self.df.diff()\n",
    "        if self.smooth_n > 0:\n",
    "            if self.smooth_func == 'mean':\n",
    "                self.df = self.df.rolling(self.smooth_n).mean().dropna(how='all')\n",
    "            elif self.smooth_func == 'max':\n",
    "                self.df = self.df.rolling(self.smooth_n).max().dropna(how='all')\n",
    "            elif self.smooth_func == 'min':\n",
    "                self.df = self.df.rolling(self.smooth_n).min().dropna(how='all')\n",
    "            elif self.smooth_func == 'sum':\n",
    "                self.df = self.df.rolling(self.smooth_n).sum().dropna(how='all')\n",
    "            elif self.smooth_func == 'median':\n",
    "                self.df = self.df.rolling(self.smooth_n).median().dropna(how='all')\n",
    "            else:\n",
    "                self.df = self.df.rolling(self.smooth_n).mean().dropna(how='all')\n",
    "        if self.norm:\n",
    "            self.df = (self.df-self.df.min())/(self.df.max()-self.df.min())\n",
    "        self.df = self.df.dropna(axis=1, how='all')\n",
    "        self.df = self.df.set_index(pd.to_datetime(self.df.index, unit='s'))\n",
    "    \n",
    "    def cluster_data(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.model = TimeSeriesKMeans(\n",
    "            n_clusters=self.n_clusters, metric=\"euclidean\", max_iter=10, n_init=2\n",
    "        ).fit(self.df.transpose().values)\n",
    "        self.df_cluster = pd.DataFrame(list(zip(self.df.columns, self.model.labels_)), columns=['metric', 'cluster'])\n",
    "        self.cluster_metrics_dict = self.df_cluster.groupby(['cluster'])['metric'].apply(lambda x: [x for x in x]).to_dict()\n",
    "        self.cluster_len_dict = self.df_cluster['cluster'].value_counts().to_dict()\n",
    "        \n",
    "    def generate_quality_scores(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for cluster in self.model.labels_:\n",
    "            self.x_corr = self.df[self.cluster_metrics_dict[cluster]].corr().abs().values\n",
    "            self.x_corr_mean = round(self.x_corr[np.triu_indices(self.x_corr.shape[0],1)].mean(),2)\n",
    "            self.cluster_quality_dict[cluster] = self.x_corr_mean\n",
    "    \n",
    "    def generate_df_cluster_meta(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.df_cluster_meta = pd.DataFrame.from_dict(self.cluster_len_dict, orient='index', columns=['n'])\n",
    "        self.df_cluster_meta.index.names = ['cluster']\n",
    "        self.df_cluster_meta['quality_score'] = self.df_cluster_meta.index.map(self.cluster_quality_dict).fillna(0)\n",
    "        self.df_cluster_meta = self.df_cluster_meta.sort_values('quality_score', ascending=False)\n",
    "        self.df_cluster_meta['valid'] = np.where(self.df_cluster_meta['n'] < self.min_n, 0, 1)\n",
    "        self.df_cluster_meta['valid'] = np.where(self.df_cluster_meta['n'] > self.max_n, 0, self.df_cluster_meta['valid'])\n",
    "        self.df_cluster_meta['valid'] = np.where(self.df_cluster_meta['quality_score'] < self.min_qs, 0, self.df_cluster_meta['valid'])\n",
    "        \n",
    "    def generate_df_cluster_centers(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.df_cluster_centers = pd.DataFrame(\n",
    "            data = self.model.cluster_centers_.reshape(\n",
    "                self.model.cluster_centers_.shape[0], \n",
    "                self.model.cluster_centers_.shape[1]\n",
    "                )\n",
    "        ).transpose()\n",
    "        self.df_cluster_centers.index = self.df.index\n",
    "        \n",
    "    def run_all(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.get_data()\n",
    "        self.preprocess_data()\n",
    "        self.cluster_data()\n",
    "        self.generate_quality_scores()\n",
    "        self.generate_df_cluster_meta()\n",
    "        self.generate_df_cluster_centers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# tests\n",
    "\n",
    "host = 'london.my-netdata.io'\n",
    "charts = get_chart_list(host)\n",
    "n_clusters = 20\n",
    "model = Clusterer(\n",
    "    hosts=host,\n",
    "    charts=charts,\n",
    "    after=-900,\n",
    "    before=0,\n",
    "    n_clusters=n_clusters\n",
    ")\n",
    "model.run_all()\n",
    "\n",
    "assert len(model.model.cluster_centers_) == n_clusters \n",
    "assert len(model.model.labels_) == len(model.df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}